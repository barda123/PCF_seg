{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to use The RCA framework to do QC on image segmentation, but using the exact same CNN used for doing the segmentation as the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json,clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mask_utils import iou\n",
    "\n",
    "from network_utils import augmentImageSequence, gpu_memory_limit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memory_limit(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model, and get them sorted in the same way as in the notebooks used to train models (i.e. same train/test split, random seed etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = './data/pericardial/wsx_round2/'\n",
    "\n",
    "#load data - these files created by extract_dcm_for_wsx.ipynb\n",
    "X = np.load(os.path.join(DataDir,'X.npy'))\n",
    "Y = np.load(os.path.join(DataDir,'Y.npy')).astype('float')\n",
    "pxArea = np.load(os.path.join(DataDir,'pxSize.npy'))\n",
    "pxSpacing = np.sqrt(pxArea)\n",
    "\n",
    "#ensure the shape is correct arrays saved were rank 3, so this changes to rank 4 (last dimension represents channels)\n",
    "X = X.reshape([*X.shape,1])\n",
    "Y = Y.reshape([*Y.shape,1])\n",
    "\n",
    "#do train/test split!\n",
    "X_train, X_test, Y_train, Y_test,pxArea_train,pxArea_test,pxSpacing_train,pxSpacing_test = train_test_split(X, Y, pxArea,pxSpacing, test_size=0.2,random_state=101)\n",
    "\n",
    "# X = X[:200,:,:,:]\n",
    "# Y = Y[:200,:,:,:]\n",
    "\n",
    "#\n",
    "# M = X.shape[0]\n",
    "# MTest = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, need to load a model which can be used for the RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a model, just need one to play with.\n",
    "modelBaseName = './data/models/mrunet_2020-04-07_09:59' #THIS MODEL IS NOT THE BEST ONE BUT HAS BEEN SELECTED TO GIVE A WIDE SPREAD IN IOU ON TRAIN AND TEST SETS\n",
    "\n",
    "#load the model archistecture\n",
    "with open( modelBaseName + '.json', 'r') as json_file:\n",
    "    model = model_from_json( json_file.read() )\n",
    "    \n",
    "#get the weights\n",
    "model.load_weights(modelBaseName + '.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE! RCA uses a network output to train a classifier which can be applied to other labelled data. I plan to use as a starting point *the actual network* that was used to generate the segmentation. However, this will not work in the obvious way - training a network on its own output will result in the cost function ==0, and thus all gradients ==0. \n",
    "\n",
    "However, thresholding the network output first will work! as the network will never output 0/1, but some numbers close to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT = Adam(learning_rate = 1e-2,\n",
    "           beta_1 = 0.9,\n",
    "           beta_2 = 0.999,\n",
    "           amsgrad = False\n",
    "          )\n",
    "\n",
    "\n",
    "def retrain_model(model,x,y):#,optimizer):\n",
    "    \n",
    "    ''''''\n",
    "    \n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]) and np.all(model.input_shape[1:] == y.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    \n",
    "    assert x.shape[0] == 1 and y.shape[0]==1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    #threshold mask so that it can be used as a target for CNN\n",
    "    y = y > 0.5\n",
    "    \n",
    "    #make a complete local copy of the model so that it is not modified globally\n",
    "    weights = model.get_weights()\n",
    "    model_local = clone_model(model)\n",
    "    model_local.set_weights(weights)\n",
    "    \n",
    "    model_local.compile(optimizer = OPT, \n",
    "                        loss = 'binary_crossentropy'\n",
    "                       )\n",
    "    \n",
    "    fit_history = model_local.fit(x=x,\n",
    "                                  y=y,\n",
    "                                  epochs = 100, #THINK ABOUT ME\n",
    "                                  steps_per_epoch= 1, #obvs\n",
    "                                  verbose=0\n",
    "                                 )\n",
    "    \n",
    "    return model_local,fit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_val,Y_val):\n",
    "    \n",
    "    '''this function takes a model (presumably retrained on a predicted mask in order to do RCA) and evaluates it on the set of masks which are known'''\n",
    "\n",
    "#     assert np.all(X.shape==Y.shape),'looks like you have mismatched your images and masks'\n",
    "#     assert X.shape[0]>1,'you should only use this on more than one image. Are you doing what you think youre doing?\n",
    "    \n",
    "    \n",
    "    Y_pred = model.predict(X_val)\n",
    "    \n",
    "    ious = np.array([iou(Y_pred[m],Y_val[m]) for m in range(Y_pred.shape[0])])\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_RCA_evaluate(model,x,X_val,Y_val):\n",
    "\n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    assert x.shape[0] == 1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    y = model.predict(x)\n",
    "    \n",
    "    rca_model,model_history = retrain_model(model,x,y)\n",
    "    \n",
    "    ious = evaluate_model(rca_model,X_val,Y_val)\n",
    "    \n",
    "    return ious,model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should look at the iou spread over the whole thing... The IOUs of all of the data we plan to use, to evaluate the *original* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueIOUs = evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "plt.hist(trueIOUs,bins = np.arange(0,1.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets just get a single datapoint to play with... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select an example image\n",
    "np.random.seed(7)\n",
    "egInd = np.random.randint(X_test.shape[0])\n",
    "\n",
    "#get the IOU that we want to predict...\n",
    "trueIOU = trueIOUs[egInd]\n",
    "\n",
    "#get the actual image out and shaped correctly\n",
    "egX = X_test[egInd,:,:].reshape(1,*model.input_shape[1:])\n",
    "\n",
    "#get all images EXCEPT that one, from both X and Y\n",
    "mask = np.ones(X_test.shape[0],dtype=bool)\n",
    "mask[egInd] = False\n",
    "X_val = X_test[mask,:,:,:]\n",
    "Y_val = Y_test[mask,:,:,:]\n",
    "\n",
    "predictedIOUs,fitHistory = predict_and_RCA_evaluate(model,egX,X_val,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the below plot represents a single example - and we can maybe have some intuitions about how to summarise the distribution etc. However, in order to sort the hyperparameters for the refit, we need to examine how the IOUs of the evaluation set change during the refitting process? \n",
    "What properties should these $\\Delta$IOUs exhibit for a well-refitted model?\n",
    " - they should change, presumably downwards?\n",
    " - should they generally move towards the true IOU of the example?\n",
    " - should they remain in the same order?\n",
    " - What should the spread of $\\Delta$ look like? It should not be uniform\n",
    " - The relative changes of the IOUs change depend on how the test point relates to the distribution of the \n",
    "      - if it is close, then the IOUs should change relatively little\n",
    "      - it it is far, they should go down a lot\n",
    "      - it is very unlikely that they should ever increase!\n",
    "      \n",
    "So, now we need to look at a picture of pre/post fit IOUs for the evaluation set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(fitHistory.history['loss'])\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(predictedIOUs,bins= np.arange(0,1.05,0.05),density=True,label = 'IOU of evaluation examples after retraining')\n",
    "\n",
    "plt.plot([trueIOU,trueIOU],plt.ylim(),c='r',label = 'true IOU')\n",
    "plt.xlabel('iou')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(trueIOUs[mask],predictedIOUs,label = 'evaluation set')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.plot([0,1],[trueIOU,trueIOU],c='r',label = 'true IOU')\n",
    "plt.plot([0,1],[0,1],c='k',label = 'line of unity')\n",
    "plt.xlabel('original IOU')\n",
    "plt.ylabel('IOU after retraining')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now I will try and do this in more systematic manner, allowing hyperparameter tuning for the optimizer, number of epochs, and optional argument for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(model, x, y, optimizer, loss = 'binary_crossentropy', epochs = 10, dataGenArgs=None):\n",
    "    \n",
    "    '''retrain a model using a single datapoint, with inputs for various hyperparameters including the '''\n",
    "    \n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]) and np.all(model.input_shape[1:] == y.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    \n",
    "    assert x.shape[0] == 1 and y.shape[0]==1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    #threshold mask so that it can be used as a target for CNN\n",
    "    y = y > 0.5\n",
    "    \n",
    "    #make a complete local copy of the model so that it is not modified globally\n",
    "    weights = model.get_weights()\n",
    "    model_local = clone_model(model)\n",
    "    model_local.set_weights(weights)\n",
    "    \n",
    "    model_local.compile(optimizer = optimizer, loss = loss)\n",
    "    \n",
    "    if dataGenArgs == None: #default option - just use the original image.\n",
    "        model_local.fit(x=x,\n",
    "                        y=y,\n",
    "                        epochs = epochs, #THINK ABOUT ME\n",
    "                        steps_per_epoch= 1, #obvs\n",
    "                        verbose=0\n",
    "                       )\n",
    "    else: #if a dict is provided with arguments for data augmentation\n",
    "        model_local.fit(augmentImageSequence(x,y,dataGenArgs,batchSize=1),\n",
    "                        epochs = epochs, #THINK ABOUT ME\n",
    "                        steps_per_epoch= 1, #obvs\n",
    "                        verbose=0\n",
    "                       )\n",
    "    \n",
    "    return model_local\n",
    "\n",
    "\n",
    "def predict_and_RCA_evaluate(model,x,X_val,Y_val,optimizer,loss='binary_crossentropy',epochs=10,dataGenArgs = None):\n",
    "\n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    assert x.shape[0] == 1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    #get the predictions from the model\n",
    "    y = model.predict(x)\n",
    "    \n",
    "    #use the predictions to retrain the model\n",
    "    rca_model = retrain_model(model, x, y, optimizer, loss = loss, epochs = epochs, dataGenArgs=dataGenArgs)\n",
    "    \n",
    "    #check the locally-retrained model against the evaluation dataset\n",
    "    ious = evaluate_model(rca_model,X_val,Y_val)\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there are considerations about which evaluation set should be used. It seems to me that thw whole point of this is to do with looking for similarities to the training set - so this should be used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hyperparameters for testing... taken from mrunet_dev.ipynb\n",
    "\n",
    "dataGenArgs = dict(rotation_range=10,\n",
    "                   width_shift_range=0.1,\n",
    "                   height_shift_range=0.1,\n",
    "                   shear_range=0.1,\n",
    "                   zoom_range=0.1,\n",
    "                   horizontal_flip=False, #DO NOT FLIP THE IMAGES FFS\n",
    "                   vertical_flip=False,\n",
    "                   fill_mode='nearest',\n",
    "                   data_format= 'channels_last',\n",
    "                   featurewise_center=False,\n",
    "                   featurewise_std_normalization=False,\n",
    "                   zca_whitening=False,\n",
    "                  )\n",
    "\n",
    "\n",
    "OPT = Adam(learning_rate = 3e-3,\n",
    "           beta_1 = 0.9,\n",
    "           beta_2 = 0.999,\n",
    "           amsgrad = False\n",
    "          )\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the true IOU for all of the test set\n",
    "trueIOUs = evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "MTest =  X_test.shape[0]\n",
    "M = X_train.shape[0]\n",
    "\n",
    "predIOUs = np.zeros((MTest,M))\n",
    "\n",
    "#loop over each test set example\n",
    "for ind in range(MTest):\n",
    "\n",
    "    predIOUs[ind,:] = predict_and_RCA_evaluate(model,egX,X_train,Y_train,optimizer=OPT,epochs=EPOCHS,dataGenArgs=dataGenArgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "\n",
    "y = np.max(predIOUs,axis=1)\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title(f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (max)')                      \n",
    "\n",
    "y = np.median(predIOUs,axis=1)            \n",
    "plt.subplot(3,1,2)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title(f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (median)')                      \n",
    "  \n",
    "y = np.mean(predIOUs,axis=1)\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title(f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (mean)')                      \n",
    "\n",
    "            \n",
    "plt.xlabel('true IOU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that suuuuuucks. Give up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0 GPU",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
