{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as keras\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "from custom_losses import binary_crossentropy_weight_balance, binary_crossentropy_weight_dict, binary_crossentropy_closeness_to_foreground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_memory_limit(memory_limit):\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        # Restrict TensorFlow to only allocate 16GB of memory on the first GPU\n",
    "        try:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit)])\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "            print('GPU memory limit allocated.')\n",
    "        except RuntimeError as e:\n",
    "            # Virtual devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "            \n",
    "gpu_memory_limit(10000) # 8GB is 1/3 of available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = './data/pericardial/wsx_20200221/'\n",
    "\n",
    "#load data - these files created by extract_dcm_for_wsx.ipynb\n",
    "X = np.load(os.path.join(DataDir,'X.npy'))\n",
    "Y = np.load(os.path.join(DataDir,'Y.npy')).astype('float')\n",
    "pxSize = np.load(os.path.join(DataDir,'pxSize.npy'))\n",
    "\n",
    "#ensure the shape is correct arrays saved were rank 3, so this changes to rank 4 (last dimension represents channels)\n",
    "X = X.reshape([*X.shape,1])\n",
    "Y = Y.reshape([*Y.shape,1])\n",
    "\n",
    "\n",
    "\n",
    "#do train/test split!\n",
    "X, X_test, Y, Y_test,pxSize,pxSize_test = train_test_split(X, Y, pxSize, test_size=0.2,random_state=101)\n",
    "\n",
    "#\n",
    "M = X.shape[0]\n",
    "MTest = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class augmentImageSequence(Sequence):\n",
    "    \n",
    "    '''class for data augmentation on matched image/mask pairs'''\n",
    "    \n",
    "    def __init__(self,Images,Masks,dataGenArgs,batchSize=1,seed=42):\n",
    "        \n",
    "        #copy raw data in\n",
    "        self.x,self.y = Images,Masks\n",
    "        self.batch_size = batchSize\n",
    "        \n",
    "        #convert to imageDataGenerators/create flow objects...\n",
    "        self.augmentIm = ImageDataGenerator(**dataGenArgs).flow(x=Images,batch_size=batchSize,seed=seed)\n",
    "        self.augmentMa = ImageDataGenerator(**dataGenArgs).flow(x=Masks, batch_size=batchSize,seed=seed)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #cheaty fake 1-stage loop, returns 1 batch from both flow objects (which will be matched)\n",
    "        for _,ims,masks in zip(range(1),self.augmentIm,self.augmentMa):        \n",
    "            \n",
    "            masks = (masks>0.5).astype('float')\n",
    "            \n",
    "            return ims,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net architecture...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,1),dropoutRate = 0):\n",
    "    inputs = layers.Input(input_size)\n",
    "    conv1 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(inputs)\n",
    "    conv1 = layers.Dropout(rate=dropoutRate)(conv1)\n",
    "    conv1 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n",
    "    conv1 = layers.Dropout(rate=dropoutRate)(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool1)\n",
    "    conv2 = layers.Dropout(rate=dropoutRate)(conv2)\n",
    "    conv2 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv2 = layers.Dropout(rate=dropoutRate)(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool2)\n",
    "    conv3 = layers.Dropout(rate=dropoutRate)(conv3)\n",
    "    conv3 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n",
    "    conv3 = layers.Dropout(rate=dropoutRate)(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool3)\n",
    "    conv4 = layers.Dropout(rate=dropoutRate)(conv4)\n",
    "    conv4 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv4)\n",
    "    conv4 = layers.Dropout(rate=dropoutRate)(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool4)\n",
    "    conv5 = layers.Dropout(rate=dropoutRate)(conv5)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv5)\n",
    "    conv5 = layers.Dropout(rate=dropoutRate)(conv5)\n",
    "\n",
    "    up6 = layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(layers.UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = layers.concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge6)\n",
    "    conv6 = layers.Dropout(rate=dropoutRate)(conv6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv6)\n",
    "    conv6 = layers.Dropout(rate=dropoutRate)(conv6)\n",
    "\n",
    "    up7 = layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(layers.UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = layers.concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge7)\n",
    "    conv7 = layers.Dropout(rate=dropoutRate)(conv7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv7)\n",
    "    conv7 = layers.Dropout(rate=dropoutRate)(conv7)\n",
    "\n",
    "    up8 = layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(layers.UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = layers.concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge8)\n",
    "    conv8 = layers.Dropout(rate=dropoutRate)(conv8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv8)\n",
    "    conv8 = layers.Dropout(rate=dropoutRate)(conv8)\n",
    "\n",
    "    up9 = layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(layers.UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = layers.concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge9)\n",
    "    conv9 = layers.Dropout(rate=dropoutRate)(conv9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = layers.Dropout(rate=dropoutRate)(conv9)\n",
    "    conv9 = layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = layers.Dropout(rate=dropoutRate)(conv9)\n",
    "    conv10 = layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#properties for data augmentation\n",
    "dataGenArgs = dict(rotation_range=5,\n",
    "                   width_shift_range=0.05,\n",
    "                   height_shift_range=0.05,\n",
    "                   shear_range=0,#0.05,\n",
    "                   zoom_range=0.05,\n",
    "                   horizontal_flip=False, #DO NOT FLIP THE IMAGES FFS\n",
    "                   vertical_flip=False,\n",
    "                   fill_mode='nearest',\n",
    "                   data_format= 'channels_last',\n",
    "                   featurewise_center=False,\n",
    "                   featurewise_std_normalization=False,\n",
    "                   zca_whitening=False,\n",
    "                  )\n",
    "\n",
    "\n",
    "earlyStop = callbacks.EarlyStopping(patience=10, #be a bit patient...\n",
    "                                    min_delta=0,\n",
    "                                    monitor='loss',\n",
    "                                    restore_best_weights=True,\n",
    "                                    mode='min',\n",
    "                                   )\n",
    "\n",
    "reduceLR = callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                       patience=5,\n",
    "                                       factor=0.3,\n",
    "                                       verbose=1,\n",
    "                                       cooldown=5,\n",
    "                                      )\n",
    "\n",
    "CALLBACKS = [earlyStop,\n",
    "             reduceLR\n",
    "            ]\n",
    "\n",
    "OPT = Adam(learning_rate = 3e-4,\n",
    "           beta_1 = 0.9,\n",
    "           beta_2 = 0.999,\n",
    "           amsgrad = False\n",
    "          )\n",
    "\n",
    "\n",
    "\n",
    "#calculate weights but over whole training set\n",
    "MULTIPLIER = Y.size/Y.sum()\n",
    "\n",
    "#other hyperparameters\n",
    "BATCHSIZE = 16 #THIS MATTERS A LOT\n",
    "DROPOUTRATE = 0\n",
    "WEIGHT_DICT = {0.:1.,1.:MULTIPLIER}\n",
    "\n",
    "#Spatial smoothing for weights\n",
    "SIGMA = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.clear_session()\n",
    "\n",
    "tf.random.set_seed(101) #FIXME!!! this is not sufficient to guarantee deterministic behaviour during fitting.\n",
    "\n",
    "model = unet(input_size=X.shape[1:],dropoutRate=DROPOUTRATE)\n",
    "\n",
    "model.compile(optimizer = OPT, \n",
    "#               loss = 'binary_crossentropy',\n",
    "#               loss = binary_crossentropy_weight_balance,\n",
    "              loss = binary_crossentropy_closeness_to_foreground(sigma=SIGMA),\n",
    "              metrics = ['accuracy',metrics.MeanIoU(num_classes=2)],\n",
    "             )\n",
    "\n",
    "fitHistory = model.fit(augmentImageSequence(X,Y,dataGenArgs,batchSize=BATCHSIZE),\n",
    "                       epochs = 100,#think about me... \n",
    "                       steps_per_epoch= M//BATCHSIZE, #obvs\n",
    "                       workers=8,\n",
    "                       use_multiprocessing=True,\n",
    "                       validation_data=(X_test,Y_test.astype('float')),\n",
    "                       callbacks=CALLBACKS,\n",
    "                       verbose=1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at how fitting has proceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(fitHistory.history['loss'],label = 'train')\n",
    "plt.plot(fitHistory.history['val_loss'],label = 'dev')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(fitHistory.history['mean_io_u'],label = 'train')\n",
    "plt.plot(fitHistory.history['val_mean_io_u'],label = 'dev')\n",
    "plt.ylabel('mean iou')\n",
    "\n",
    "plt.xlabel('epoch #')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the  distribution of IoU (rather than just the mean)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(yTrue,yPred):\n",
    "    '''intersection-over-union score'''\n",
    "    \n",
    "    yTrue = yTrue>=0.5\n",
    "    yPred = yPred>=0.5\n",
    "    \n",
    "    intersection = np.sum(np.logical_and(yTrue,yPred))\n",
    "    \n",
    "    union = np.sum(np.logical_or(yTrue,yPred))\n",
    "    \n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTest = model.predict(X_test)\n",
    "\n",
    "predTrain = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over th eexample axis, calculating IoU for each image separately\n",
    "plt.hist([iou(Y[m,:,:,:], predTrain[m,:,:]) for m in range(MTest)] , bins = np.arange(0,1.05,0.05), density=True, alpha=0.5, label = 'Train')\n",
    "plt.hist([iou(Y[m,:,:,:], predTest[m,:,:]) for m in range(MTest)] ,  bins = np.arange(0,1.05,0.05), density=True, alpha=0.5, label = 'Test')\n",
    "\n",
    "plt.xlabel('iou')\n",
    "plt.ylabel('probability density')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do predicted **areas** of fat match? That is what the project is all about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "areasPredTrain = np.sum(predTrain,axis=(1,2,3)) * pxSize\n",
    "areasTrueTrain = np.sum(Y,axis=(1,2,3)) * pxSize\n",
    "\n",
    "areasPredTest = np.sum(predTest,axis=(1,2,3)) * pxSize_test\n",
    "areasTrueTest = np.sum(Y_test,axis=(1,2,3)) * pxSize_test\n",
    "\n",
    "plt.scatter(areasTrueTrain,areasPredTrain,label = 'train')\n",
    "plt.scatter(areasTrueTest,areasPredTest,label = 'test')\n",
    "\n",
    "r2,p = pearsonr(areasTrueTest,areasPredTest)\n",
    "\n",
    "plt.title('for test set, R^2 = ' + str(r2) + ', p = ' + str(p))\n",
    "\n",
    "plt.xlabel('human area (mm^2)')\n",
    "\n",
    "plt.ylabel('machine area (mm^2)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a few examples of the training set segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negs = 15\n",
    "\n",
    "sample = np.random.randint(low=0,high=X.shape[0],size=negs)\n",
    "\n",
    "plt.figure(figsize = (15,5*negs))\n",
    "for ind,eg in enumerate(sample):\n",
    "    \n",
    "    plt.subplot(negs,3,ind*3+1)\n",
    "    plt.imshow(np.squeeze(X[eg,:]),vmin=0,vmax=1)\n",
    "\n",
    "    plt.subplot(negs,3,ind*3+2)\n",
    "    plt.imshow(np.squeeze(Y[eg,:]),vmin=0,vmax=1)\n",
    "    \n",
    "    plt.subplot(negs,3,ind*3+3)\n",
    "    plt.imshow(np.squeeze(predTrain[eg,:]),vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5*MTest))\n",
    "\n",
    "\n",
    "f = True\n",
    "\n",
    "#loop over rows\n",
    "for ind in range(MTest): #FIXME when I have more data, should take a random sample from test set rather than the whole thing\n",
    "    \n",
    "    if ind>0:\n",
    "        f= False\n",
    "    \n",
    "    \n",
    "    #Show original image\n",
    "    plt.subplot(MTest,3,ind*3+1)\n",
    "    plt.imshow(np.squeeze(X_test[ind,:]),vmin=0,vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if f:\n",
    "        plt.title('image')\n",
    "    \n",
    "    #show human segmentation\n",
    "    plt.subplot(MTest,3,ind*3+2)\n",
    "    plt.imshow(np.squeeze(Y_test[ind,:]),vmin=0,vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if f:\n",
    "        plt.title('human')\n",
    "    \n",
    "    #show automated segmentation\n",
    "    plt.subplot(MTest,3,ind*3+3)\n",
    "    plt.imshow(np.squeeze(predTest[ind,:]),vmin=0,vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if f:\n",
    "        plt.title('machine')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0 GPU",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
