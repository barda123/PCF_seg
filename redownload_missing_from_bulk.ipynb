{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exists so that we can try and clean up the data missing from UK biobank... preliminary work suggests that we can download anythign that is listed in the bulk files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import glob\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and parse all .bulk files, looking only at their union, and subset for those referring to CMR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bulk files, this will produce a list of strings\n",
    "bulkFiles = ['/workspace/storage/restricted-biobank/releases/REVISION_May2019/ID-27289/ukb27289.bulk','/workspace/storage/restricted-biobank/releases/REVISION_May2019/ID-29801/ukb29801.bulk']\n",
    "\n",
    "bulk = []\n",
    "\n",
    "for b in bulkFiles:\n",
    "    with open(b,'r') as f:\n",
    "        bulk+=f.readlines()\n",
    "\n",
    "#uniqueify\n",
    "bulk = list(set(bulk))\n",
    "\n",
    "print('total of ' + str(len(bulk)) + ' files listed in bulk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dictionaries for mapping between human-readable names of zipfiles, and the UKB codes\n",
    "\n",
    "code2name = {'20207_2_0':'_scout',\n",
    "             '20208_2_0':'_longaxis',\n",
    "             '20209_2_0':'_shortaxis',\n",
    "             '20210_2_0':'_aorticdistensibility',\n",
    "             '20211_2_0':'_cinetagging',\n",
    "             '20212_2_0':'_lvot',\n",
    "             '20213_2_0':'_bloodflow',\n",
    "             '20214_2_0':'_experimentalshmollisequence',\n",
    "            }\n",
    "\n",
    "name2code = {v:k for k,v in code2name.items()}\n",
    "\n",
    "#loop over bulk list, keeping elements which have been marked as CMR\n",
    "bulk = [f for f in bulk if f[8:-1] in code2name.keys()]\n",
    "\n",
    "print('subsetted for only cmr, there are ' + str(len(bulk)) + ' files.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the resulting list into names of zipfiles. \n",
    "\n",
    "Check for the existence of those zipfiles at the appropriate location, and subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk2zip(bulk):\n",
    "    \n",
    "    #remove newline characters and any file extension that may pop up\n",
    "    bulk = os.path.splitext(bulk.replace('\\n',''))[0]\n",
    "    \n",
    "    feid = bulk[:7]\n",
    "    \n",
    "    code = bulk[8:]\n",
    "    \n",
    "    extname = code2name[code]\n",
    "    \n",
    "    return  feid + extname + '.zip'\n",
    "\n",
    "\n",
    "def zip2path(mainDir,zipName):\n",
    "    \n",
    "    feid = zipName[:7]\n",
    "    \n",
    "    path = os.path.join(mainDir,feid[:2] + 'xxxxx',feid,zipName)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(mainDir,bulk):\n",
    "    \n",
    "    '''take a bulk field and check whether its zip equivalent exists in expected location within the file hierarchy. returns True if missing!'''\n",
    "\n",
    "    zipName = bulk2zip(bulk)\n",
    "    \n",
    "    zipPath = zip2path(mainDir,zipName)\n",
    "    \n",
    "    if os.path.isfile(zipPath):\n",
    "        \n",
    "        return False #because the file IS THERE\n",
    "    \n",
    "    else: #if the file is NOT found\n",
    "        \n",
    "        #check special case for misspelled aorticdistensibility\n",
    "        if 'aorticdistensibility' in zipName:\n",
    "            #check for the alternative spelling\n",
    "            zipPath = zipPath.replace('aorticdistensibility','aorticdistensibilty')\n",
    "            #true if the file is not there...\n",
    "            return not os.path.isfile(zipPath)\n",
    "        \n",
    "        #otherwise jusr return true (no other misspelligs I am aware of currently)\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "\n",
    "#create the root file which can contain the subtree of downloaded/renamed files\n",
    "mergable = './data/downloaded'\n",
    "if not os.path.isdir(mergable):\n",
    "    os.mkdir(mergable)\n",
    "    \n",
    "# notThere = [check_file('./data/imaging_by_participant',f) and check_file(mergable,f) for f in bulk]\n",
    "\n",
    "notThere = [check_file('./data/imaging_by_participant',f) for f in bulk]\n",
    "\n",
    "print('of ' + str(len(bulk)) + ' cmr files listed in bulk, there are ' + str(sum(notThere)) + ' files missing (' + str(100*sum(notThere)//len(bulk)) + '%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into batches of 500 and use ukbfetch. Write logs so that download failures can be checked later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch = list(compress(bulk,notThere))\n",
    "\n",
    "nBatches = 1 + len(fetch)//500#batches of 500 files at a time\n",
    "\n",
    "#create a folder for batches and their corresponding logs\n",
    "batchDir = './data/batches'\n",
    "if not os.path.isdir(batchDir):\n",
    "    os.mkdir(batchDir)\n",
    "\n",
    "for b in range(nBatches):\n",
    "    \n",
    "    clear_output()\n",
    "    print('downloading batch ' + str(b+1) + '/' + str(nBatches))\n",
    "    \n",
    "    #write a bulk file for the current batch of 500\n",
    "    batchFile = os.path.join(batchDir,'batch' + str(b).zfill(3) + '.bulk')\n",
    "    \n",
    "    with open(batchFile,'w+') as f:\n",
    "        f.write(''.join(fetch[b*500:(b+1)*500]))\n",
    "\n",
    "    #invoke ukbfetch, write log\n",
    "    outFile = batchFile.replace('.bulk','')\n",
    "    os.system('ukbfetch -a./data/k2964.key -b' + batchFile + ' -o' + outFile)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#get the list of files which have actually been downloaded\n",
    "\n",
    "downloadedLists = glob.glob(os.path.join(batchDir,'*.lis'))\n",
    "\n",
    "downloaded = []\n",
    "for l in downloadedLists:\n",
    "    with open(l,'r') as f:\n",
    "        downloaded += f.readlines()\n",
    "        \n",
    "print('from ' + str(len(fetch)) + ' attempted downloads, ' +str(len(downloaded)) + ' succeeded (' + str(100*len(downloaded)//len(fetch)) + '%).')\n",
    "\n",
    "#no need to log these... any failures will be re-attempted as part of the next run. Also so far there have been no failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the integrity of the zipfiles (!), and move valid ones into a directory structure consistent with that already used so it can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zipNames = [bulk2zip(b) for b in downloaded]\n",
    "\n",
    "corruptedFiles = []\n",
    "\n",
    "mergableZipPaths = [zip2path(mergable,z) for z in zipNames]\n",
    "\n",
    "legitSource = []\n",
    "legitDest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d,m in zip(downloaded,mergableZipPaths):\n",
    "    try:\n",
    "        _ = zipfile.ZipFile(d) #which will fail if the zip is malformed in some way\n",
    "        \n",
    "        legitSource += [d]\n",
    "        legitDest += [m]\n",
    "        \n",
    "    except:\n",
    "        #if zip is corrupted, add to list in bulk format so it can be recorded\n",
    "        bulkName = list(d.replace('.zip',''))\n",
    "        bulkName[7] = ' '\n",
    "        bulkName = ''.join(bulkName)\n",
    "        \n",
    "        corruptedFiles.append(bulkName)\n",
    "        \n",
    "#write out the list of failed/corrupted files...\n",
    "with open('./data/batches/corrupted.bulk','w+') as f:\n",
    "    f.write(''.join(corruptedFiles))\n",
    "\n",
    "    \n",
    "print('of ' + str(len(fetch)) +' downloaded files, ' + str(len(corruptedFiles)) + ' gave corrupted zips.')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,d in zip(legitSource,legitDest):\n",
    "    \n",
    "    destDir = os.path.dirname(d)\n",
    "#     pri\n",
    "    if not os.path.isdir(destDir):\n",
    "        os.makedirs(destDir)\n",
    "    #do the move\n",
    "    os.rename(s,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up/remove corrupted files.\n",
    "[os.remove(f.replace(' ','_').replace('\\n','.zip')) for f in corruptedFiles];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
