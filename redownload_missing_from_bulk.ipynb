{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exists so that we can try and clean up the data missing from UK biobank... preliminary work suggests that we can download anythign that is listed in the bulk files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and parse all .bulk files, looking only at their union, and subset for those referring to CMR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bulk files, this will produce a list of strings\n",
    "bulkFiles = ['/workspace/storage/restricted-biobank/releases/REVISION_May2019/ID-27289/ukb27289.bulk','/workspace/storage/restricted-biobank/releases/REVISION_May2019/ID-29801/ukb29801.bulk']\n",
    "\n",
    "bulk = []\n",
    "\n",
    "for b in bulkFiles:\n",
    "    with open(b,'r') as f:\n",
    "        bulk+=f.readlines()\n",
    "\n",
    "#uniqueify\n",
    "bulk = list(set(bulk))\n",
    "\n",
    "print('total of ' + str(len(bulk)) + ' files listed in bulk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dictionaries for mapping between human-readable names of zipfiles, and the UKB codes\n",
    "\n",
    "code2name = {'20207_2_0':'_scout',\n",
    "             '20208_2_0':'_longaxis',\n",
    "             '20209_2_0':'_shortaxis',\n",
    "             '20210_2_0':'_aorticdistensibility',\n",
    "             '20211_2_0':'_cinetagging',\n",
    "             '20212_2_0':'_lvot',\n",
    "             '20213_2_0':'_bloodflow',\n",
    "             '20214_2_0':'_experimentalshmollisequence',\n",
    "            }\n",
    "\n",
    "name2code = {v:k for k,v in code2name.items()}\n",
    "\n",
    "#loop over bulk list, keeping elements which have been marked as CMR\n",
    "bulk = [f for f in bulk if f[8:-1] in code2name.keys()]\n",
    "\n",
    "print('subsetted for only cmr, there are ' + str(len(bulk)) + ' files.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the resulting list into names of zipfiles. \n",
    "\n",
    "Check for the existence of those zipfiles at the appropriate location, and subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk2zip(bulk):\n",
    "    \n",
    "    feid = bulk[:7]\n",
    "    \n",
    "    code = bulk[8:-1]\n",
    "    \n",
    "    extname = code2name[code]\n",
    "    \n",
    "    return  feid + extname + '.zip'\n",
    "\n",
    "\n",
    "def zip2path(mainDir,zipName):\n",
    "    \n",
    "    feid = zipName[:7]\n",
    "    \n",
    "    path = os.path.join(mainDir,feid[:2] + 'xxxxx',feid,zipName)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(mainDir,bulk):\n",
    "    \n",
    "    '''take a bulk field and check whether its zip equivalent exists in expected location within the file hierarchy. returns True if missing!'''\n",
    "\n",
    "    zipName = bulk2zip(bulk)\n",
    "    \n",
    "    zipPath = zip2path(mainDir,zipName)\n",
    "    \n",
    "    if os.path.isfile(zipPath):\n",
    "        \n",
    "        return False #because the file IS THERE\n",
    "    \n",
    "    else: #if the file is NOT found\n",
    "        \n",
    "        #check special case for misspelled aorticdistensibility\n",
    "        if 'aorticdistensibility' in zipName:\n",
    "            #check for the alternative spelling\n",
    "            zipPath = zipPath.replace('aorticdistensibility','aorticdistensibilty')\n",
    "            #true if the file is not there...\n",
    "            return not os.path.isfile(zipPath)\n",
    "        \n",
    "        #otherwise jusr return true (no other misspelligs I am aware of currently)\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "\n",
    "#create the root file which can contain the subtree of downloaded/renamed files\n",
    "mergable = './data/downloaded'\n",
    "if not os.path.isdir(mergable)\n",
    "    os.mkdir(mergable)\n",
    "    \n",
    "notThere = [check_file('./data/imaging_by_participant',f) and check_file(mergable,f) for f in bulk]\n",
    "\n",
    "print('of ' + str(len(bulk)) + ' cmr files listed in bulk, there are ' + str(sum(notThere)) + ' files missing (' + str(100*sum(notThere)//len(bulk)) + '%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into batches of 500 and use ukbfetch. Write logs so that download failures can be checked later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch = list(compress(bulk,notThere))\n",
    "\n",
    "nBatches = 1 + len(fetch)//500#batches of 500 files at a time\n",
    "\n",
    "#create a folder for batches and their corresponding logs\n",
    "batchDir = './data/batches'\n",
    "if not os.path.isdir(batchDir):\n",
    "    os.mkdir(batchDir)\n",
    "\n",
    "for b in range(nBatches):\n",
    "    \n",
    "    #write a bulk file for the current batch of 500\n",
    "    batchFile = os.path.join(batchDir,'batch' + str(b).zfill(3) + '.bulk')\n",
    "    \n",
    "    with open(batchFile,'w+') as f:\n",
    "        f.write(''.join(fetch[b*500:(b+1)*500]))\n",
    "\n",
    "    #invoke ukbfetch, write log\n",
    "    outFile = batchFile.replace('.bulk','')\n",
    "    os.system('ukbfetch -a./data/k2964.key -b' + batchFile + ' -o' + outFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the integrity of the zipfiles (!), and move valid ones into a directory structure consistent with that already used so it can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadedNames = [b.replace('\\n','.zip') for b in fetch]\n",
    "\n",
    "zipNames = [bulk2zip(b) for b in fetch]\n",
    "\n",
    "corruptedFiles = []\n",
    "\n",
    "mergableZipPaths = [zip2path(mergable,z) for z in zipNames]\n",
    "\n",
    "for d,m,b in zip(downloadedNames,mergableZipPaths,fetch):\n",
    "    try:\n",
    "        _ = zipfile.ZipFile(d) #which will fail if the zip is malformed in some way, or if the download failed\n",
    "        \n",
    "        #move the file to a sensible location\n",
    "        os.rename(d,m)\n",
    "    except:\n",
    "        corruptedFiles.append(b)\n",
    "        os.remove(d)\n",
    "        \n",
    "#write out the list of failed/corrupted files...\n",
    "with open('./data/batches/failures.bulk','w+') as f:\n",
    "    f.write(''.join(corruptedFiles))\n",
    "\n",
    "    \n",
    "print('of ' + str(len(fetch)) +' files to be downloaded, ' + str(len(corruptedFiles)) + ' failed.')        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
