{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dcm\n",
    "\n",
    "from Converters import parse_cvi42_xml\n",
    "\n",
    "import pickle\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import re\n",
    "\n",
    "from matplotlib.path import Path as mPath\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsxDir = './data/pericardial/wsx_round2/'#directory where finalised wsx files are kept.\n",
    "\n",
    "pairedDir = os.path.join(wsxDir,'paired') #subdirectory for outputs.\n",
    "\n",
    "if not os.path.isdir(pairedDir):\n",
    "    os.mkdir(pairedDir)\n",
    "\n",
    "wsxFiles = glob.glob(os.path.join(wsxDir,'*.cvi42wsx'))\n",
    "\n",
    "#parse all the wsx files into pickles.\n",
    "[parse_cvi42_xml.parseFile(w,output_dir=pairedDir) for w in wsxFiles]\n",
    "\n",
    "#get only the pickle files referring to individual slice names - i.e. named using uids.\n",
    "pickles = glob.glob(os.path.join(pairedDir,'*.pickle'))\n",
    "correctPickle = re.compile('[\\d.]*.pickle') #only numeric filenames... heuristic but probably good enough\n",
    "pickles = [p for p in pickles if correctPickle.match(os.path.basename(p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_extract_relevant_dcm(picklePaths, outputDir = '.',zippedDataPath='data/imaging_by_participant',zipFilter='[\\S\\s]*'):\n",
    "    '''takes a pickle file, or list/array thereof (presumablty exported from a cvi42wsx file) and finds the correctn corresponding dicom file\n",
    "    picklePaths: list or array of paths to pickle files created by parseFile()\n",
    "    outputDir: where to put the dicom file\n",
    "    zippedDataPath: the top-level directory within which all zipped dicom files reside.\n",
    "    zipFilter: a regex that can be used to filter for only the zipfiles we care about.\n",
    "    '''\n",
    "        \n",
    "    #if 1 file, make it a list\n",
    "    if type(picklePaths) == str:\n",
    "        picklePaths = [picklePaths]\n",
    "    \n",
    "    #use names of pickles to get names of their (expected) dicom file\n",
    "    dicomNames = [os.path.basename(p.replace('.pickle','.dcm')) for p in picklePaths]\n",
    "    #uniqueify\n",
    "    dicomNames = list(set(dicomNames))\n",
    "    \n",
    "    #create list of the outputs!\n",
    "    dicomPaths = [os.path.join(outputDir,d) for d in dicomNames] \n",
    "    #check for dicom files in the output directory, so we can subset and avoid duplicated work\n",
    "    alreadyThere = [os.path.basename(f) for f in glob.glob(os.path.join(outputDir,'*.dcm'))]\n",
    "    dicomNames = list(set(dicomNames) - set(alreadyThere))\n",
    "    \n",
    "    if len(dicomNames)==0:\n",
    "        print('no work to do!!')\n",
    "    else:\n",
    "        print('getting list of all zipfiles in path...')\n",
    "        #get list of ALL dicoms within top-level directory\n",
    "        allZips = glob.glob(os.path.join(zippedDataPath,'**','*.zip'),recursive = True)\n",
    "        \n",
    "        \n",
    "        #filter names of zips using regex, and give some idea of how much this has achieved.\n",
    "        nAllZips = len(allZips)\n",
    "        zipFilter = re.compile(zipFilter)\n",
    "        allZips = [z for z in allZips if zipFilter.match(os.path.basename(z))]\n",
    "        nFilteredZips = len(allZips)\n",
    "        print('regex filtering reduced ' + str(nAllZips) + ' zipfiles to ' + str(nFilteredZips) )\n",
    "\n",
    "        i=0\n",
    "        while len(dicomNames) > 0 and i < len(allZips):\n",
    "            zf = ZipFile(allZips[i])\n",
    "\n",
    "            contents = zf.namelist()\n",
    "            for d in dicomNames:\n",
    "                if d in contents:\n",
    "                    zf.extract(d,path=outputDir)\n",
    "                    dicomNames.remove(d)\n",
    "                    #give some indication of how much is done\n",
    "                    print(str(100*((len(dicomPaths) - len(dicomNames))/len(dicomNames))) + '% found and extracted')\n",
    "            zf.close()\n",
    "            i+=1\n",
    "                        \n",
    "        if len(dicomNames) != 0:\n",
    "            print('warning: not all dicoms found. consider broadening your regex. files not found:\\n' + '\\n'.join(dicomNames))\n",
    "\n",
    "    return dicomPaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicomPaths = find_and_extract_relevant_dcm(picklePaths=pickles,outputDir=pairedDir,zipFilter='[\\S\\s]*_longaxis') #as we are only looking for long axis images.\n",
    "\n",
    "#subset for those with image...\n",
    "dcmFound = [os.path.isfile(d) for d in dicomPaths]\n",
    "\n",
    "pickles = list(compress(pickles,dcmFound))\n",
    "dicomPaths = list(compress(dicomPaths,dcmFound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, it is possible that dicom and pickle paths are not in the same order... check that they are matched.\n",
    "pickles = sorted(pickles)\n",
    "dicomPaths = sorted(dicomPaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_slice(X, L):\n",
    "    L = np.asarray(L)\n",
    "    shape = np.array(X.shape)\n",
    "\n",
    "    # verify assumptions\n",
    "    assert L.shape == (X.ndim,)\n",
    "    assert ((0 <= L) & (L <= shape)).all()\n",
    "\n",
    "    # calculate start and end indices for each axis\n",
    "    starts = (shape - L) // 2\n",
    "    stops = starts + L\n",
    "\n",
    "    # convert to a single index\n",
    "    idx = tuple(np.s_[a:b] for a, b in zip(starts, stops))\n",
    "    return X[idx]\n",
    "\n",
    "def pad_voxels(voxels,pad_size):\n",
    "    \n",
    "    nx,ny = voxels.shape    \n",
    "\n",
    "    #calculate edges and create tuple to ensure correct dimension\n",
    "    xedge = np.maximum((pad_size[0] - nx) //2,0)\n",
    "    yedge = np.maximum((pad_size[1] - ny) //2,0)\n",
    "    pad_width = ( (int(np.floor(xedge)),int(np.ceil(xedge))) , (int(np.floor(yedge)),int(np.ceil(yedge))) )\n",
    "\n",
    "    voxels= np.pad(voxels,pad_width,'constant')\n",
    "    \n",
    "    if np.any([nx,ny] > pad_size): \n",
    "        warnings.warn('Image is larger than padding dimension you specified, so you are losing pixels at the edges')\n",
    "        \n",
    "        voxels = centered_slice(voxels, pad_size)\n",
    "    \n",
    "    return voxels\n",
    "\n",
    "\n",
    "\n",
    "def load_image_and_mask(picklePath,dicomPath,pad_size = None, collapse=True,labelFilter=''):\n",
    "\n",
    "    '''takes paths to matched files - a pickle output from parse cvi42wsx, and the corresponding dicom\n",
    "    padSize is the size of the output images - it currently allows cropping or padding.\n",
    "    labelFilter allows passing in of a regex string for the NAMES of the different contours. \n",
    "    collapse specifies whether the different contours are or-ed (i.e. forcing a single-channel boolean mask)\n",
    "    WARNING - will have unexpected behaviour with collapse=False and heterogeneous labels \n",
    "    '''\n",
    "    \n",
    "    #load dicom image.\n",
    "    image = dcm.dcmread(dicomPath,stop_before_pixels=False)\n",
    "    \n",
    "    #load the pickled contour\n",
    "    with open(picklePath,'rb') as f:\n",
    "        contour = pickle.load(f)\n",
    "    \n",
    "    #consider case where there are >=1 contours per image\n",
    "    nContours = len(contour)\n",
    "    \n",
    "    #get dimensions of image\n",
    "    nx,ny = image.pixel_array.shape\n",
    "    \n",
    "    #create indexers for filling in mask\n",
    "    x,y = np.meshgrid(range(nx),range(ny))\n",
    "    x = x.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    xy = np.concatenate((x,y),axis=1) #xy matrix\n",
    "    \n",
    "#     print(xy.shape)\n",
    "    \n",
    "    #create mask which can contain all contours.\n",
    "    mask = np.zeros((*image.pixel_array.shape,nContours),dtype = 'bool')\n",
    "    \n",
    "    #if no filter specified, the default one will always match\n",
    "    labelFilter = re.compile(labelFilter)\n",
    "    \n",
    "    for ind,c in enumerate(sorted(contour.keys())):\n",
    "        #if regex for the name of the contour is correct, use it... default argument for labelFilter will always match\n",
    "        if labelFilter.match(c):\n",
    "            #get grid points inside contour\n",
    "            path = mPath(contour[c])\n",
    "            inContour = path.contains_points(xy)\n",
    "            #index into mask...\n",
    "            mask[y[inContour],x[inContour],ind] = True\n",
    "    \n",
    "    #if specified, collapse down to 1D representation\n",
    "    if collapse:\n",
    "        mask = np.max(mask,axis=2)\n",
    "        \n",
    "    #extract the raw pixel values from the dicom file, and normalise to 0-1\n",
    "    minVal = np.min(image.pixel_array)\n",
    "    maxVal = np.max(image.pixel_array)\n",
    "    im = (image.pixel_array - minVal) / (maxVal - minVal)\n",
    "    \n",
    "    #get size of pixels(required for downstream analysis)\n",
    "    pxSize = np.product(image.PixelSpacing)\n",
    "    \n",
    "    if pad_size != None:\n",
    "        \n",
    "        im = pad_voxels(im,pad_size)\n",
    "        mask = pad_voxels(mask,pad_size)\n",
    "\n",
    "    return im,mask,pxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all files, and put into arrays of dimension (m,x,y)\n",
    "PADSIZE = [192,208]\n",
    "\n",
    "m = len(pickles)\n",
    "X = np.zeros((m,*PADSIZE))\n",
    "Y = np.zeros((m,*PADSIZE),dtype='bool')\n",
    "pxSize = np.zeros(m)\n",
    "\n",
    "for ind,(p,d) in enumerate(zip(pickles,dicomPaths)):\n",
    "    \n",
    "    X[ind,:,:],Y[ind,:,:],pxSize[ind] = load_image_and_mask(p,d,PADSIZE,labelFilter='freeDraw')\n",
    "    \n",
    "#remove images without any contours. \n",
    "use = np.max(np.max(Y,axis=2),axis=1) >0 \n",
    "X = X[use,:,:]\n",
    "Y = Y[use,:,:]\n",
    "\n",
    "#also filter pickles and dicom paths for later, just in case\n",
    "pickles = list(compress(pickles,use))\n",
    "dicomPaths = list(compress(dicomPaths,use))\n",
    "\n",
    "# save X and Y for use in the ML dev notebook\n",
    "np.save(os.path.join(wsxDir,'X.npy'),X)\n",
    "np.save(os.path.join(wsxDir,'Y.npy'),Y)\n",
    "np.save(os.path.join(wsxDir,'pxSize.npy'),pxSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics for the area of pcf....\n",
    "\n",
    "fatArea = np.sum(Y,axis=(1,2)) * pxSize/100 #in mm^2\n",
    "\n",
    "plt.hist(fatArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (10,5*m))\n",
    "#lets ave a look\n",
    "for i in range(m):\n",
    "    plt.subplot(m,2,i*2+1)\n",
    "    plt.imshow(X[i,:,:])\n",
    "    plt.subplot(m,2,i*2+2)\n",
    "    plt.imshow(Y[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0 GPU",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
