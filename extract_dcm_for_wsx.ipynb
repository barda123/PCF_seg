{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Converters import parse_cvi42_xml\n",
    "\n",
    "import pickle\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mask_utils import load_image,load_image_and_mask,show_image_with_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsxDir = './data/pericardial/wsx_round2/'#directory where finalised wsx files are kept.\n",
    "\n",
    "pairedDir = os.path.join(wsxDir,'paired') #subdirectory for outputs.\n",
    "\n",
    "if not os.path.isdir(pairedDir):\n",
    "    os.mkdir(pairedDir)\n",
    "\n",
    "wsxFiles = glob.glob(os.path.join(wsxDir,'*.cvi42wsx'))\n",
    "\n",
    "#parse all the wsx files into pickles.\n",
    "# [parse_cvi42_xml.parseFile(w,output_dir=pairedDir) for w in wsxFiles]\n",
    "\n",
    "#get only the pickle files referring to individual slice names - i.e. named using uids.\n",
    "pickles = glob.glob(os.path.join(pairedDir,'*.pickle'))\n",
    "\n",
    "pickles = [p for p in pickles if '_contours_dct.pickle' not in p] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_extract_relevant_dcm(fileNames, outputDir = '.',zippedDataPath='data/imaging_by_participant',zipFilter='[\\S\\s]*'):\n",
    "    '''takes a pickle file, or list/array thereof (presumablty exported from a cvi42wsx file) and finds the correctn corresponding dicom file\n",
    "    fileNames: list or array of paths to pickle files (or corresponding dicom files) created by parseFile()\n",
    "    outputDir: where to put the dicom file\n",
    "    zippedDataPath: the top-level directory within which all zipped dicom files reside.\n",
    "    zipFilter: a regex that can be used to filter for only the zipfiles we care about.\n",
    "    '''\n",
    "        \n",
    "    #if 1 file, make it a list\n",
    "    if type(fileNames) == str:\n",
    "        fileNames = [fileNames]\n",
    "    \n",
    "    #use names of pickles to get names of their (expected) dicom file\n",
    "    dicomNames = [os.path.basename(p.replace('.pickle','.dcm')) for p in fileNames]\n",
    "    \n",
    "    #uniqueify\n",
    "    dicomNames = list(set(dicomNames))\n",
    "    \n",
    "    #create list of the outputs!\n",
    "    dicomPaths = [os.path.join(outputDir,d) for d in dicomNames] \n",
    "    #check for dicom files in the output directory, so we can subset and avoid duplicated work\n",
    "    alreadyThere = [os.path.basename(f) for f in glob.glob(os.path.join(outputDir,'*.dcm'))]\n",
    "    dicomNames = list(set(dicomNames) - set(alreadyThere))\n",
    "    \n",
    "    if len(dicomNames)==0:\n",
    "        print('no work to do!!')\n",
    "    else:\n",
    "        print('getting list of all zipfiles in path...')\n",
    "        #get list of ALL dicoms within top-level directory   \n",
    "        allZips = glob.glob(os.path.join(zippedDataPath,'**','*.zip'),recursive = True)\n",
    "        \n",
    "        \n",
    "        #filter names of zips using regex, and give some idea of how much this has achieved.\n",
    "        nAllZips = len(allZips)\n",
    "        zipFilter = re.compile(zipFilter)\n",
    "        allZips = [z for z in allZips if zipFilter.match(os.path.basename(z))]\n",
    "        nFilteredZips = len(allZips)\n",
    "        print('regex filtering reduced ' + str(nAllZips) + ' zipfiles to ' + str(nFilteredZips) )\n",
    "\n",
    "        i=0\n",
    "        while len(dicomNames) > 0 and i < len(allZips):\n",
    "            zf = ZipFile(allZips[i])\n",
    "\n",
    "            contents = zf.namelist()\n",
    "            for d in dicomNames:\n",
    "                if d in contents:\n",
    "                    zf.extract(d,path=outputDir)\n",
    "                    dicomNames.remove(d)\n",
    "                    #give some indication of how much is done\n",
    "#                     print(str(100*((len(dicomPaths) - len(dicomNames))/len(dicomNames))) + '% found and extracted')\n",
    "            zf.close()\n",
    "            i+=1\n",
    "                        \n",
    "        if len(dicomNames) != 0:\n",
    "            print('warning: not all dicoms found. consider broadening your regex. files not found:\\n' + '\\n'.join(dicomNames))\n",
    "\n",
    "    return dicomPaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicomPaths = find_and_extract_relevant_dcm(fileNames=pickles,outputDir=pairedDir,zipFilter='[\\S\\s]*_longaxis') #as we are only looking for long axis images.\n",
    "\n",
    "#now, it is possible that dicom and pickle paths are not in the same order... check that they are matched.\n",
    "pickles = sorted(pickles)\n",
    "dicomPaths = sorted(dicomPaths)\n",
    "\n",
    "#subset for those with image...\n",
    "dcmFound = [os.path.isfile(d) for d in dicomPaths]\n",
    "\n",
    "pickles = list(compress(pickles,dcmFound))\n",
    "dicomPaths = list(compress(dicomPaths,dcmFound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preload images and spacings so we can select parameters\n",
    "info = pd.DataFrame({'dicom':dicomPaths})\n",
    "\n",
    "images,spacings = zip(*info['dicom'].apply(load_image))\n",
    "\n",
    "info.loc[:,'xDim'],info.loc[:,'yDim'] = zip(*[i.shape for i in images])\n",
    "\n",
    "info.loc[:,'xSpacing'],info.loc[:,'ySpacing'] = zip(*spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=info[\"xSpacing\"], y=info[\"ySpacing\"], kind='hex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=info[\"xDim\"], y=info[\"yDim\"], kind='hex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick resolution and spacing based on the above plots....\n",
    "\n",
    "PADSIZE = np.concatenate([info['xDim'].mode().values,info['yDim'].mode().values])\n",
    "\n",
    "print('modal image size = ' + str(PADSIZE))\n",
    "\n",
    "PXSPACING = np.concatenate([info['xSpacing'].mode().values, info['ySpacing'].mode().values])\n",
    "\n",
    "print('modal image resolution = ' + str(PXSPACING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all files, and put into arrays of dimension (m,x,y)\n",
    "PADSIZE = [208,208]\n",
    "PXSPACING = [1.82692313 1.82692313]\n",
    "\n",
    "#write out the details for image sizes and pixel spacing so they can be reused in other notebooks\n",
    "pickle.dump(PADSIZE,open(os.path.join('data','PADSIZE.pickle'),'wb'))\n",
    "pickle.dump(PXSPACING,open(os.path.join('data','PXSPACING.pickle'),'wb'))\n",
    "\n",
    "#preallocate arrays..\n",
    "m = len(pickles)\n",
    "X = np.zeros((m,*PADSIZE))\n",
    "Y = np.zeros((m,*PADSIZE),dtype='bool')\n",
    "pxSize = np.zeros((m,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,(p,d) in enumerate(zip(pickles,dicomPaths)):\n",
    "    X[ind,:,:],Y[ind,:,:],pxSize[ind,:] = load_image_and_mask(p,d,PXSPACING,PADSIZE,labelFilter='freeDraw')\n",
    "\n",
    "pxSize = np.product(pxSize,axis=-1)\n",
    "#remove images without any contours. \n",
    "use = np.max(np.max(Y,axis=2),axis=1) >0 \n",
    "if np.any(~use):\n",
    "    print('check your input data regarding, there are ' + str((~use).sum()) + ' images with no mask')\n",
    "X = X[use,:,:]\n",
    "Y = Y[use,:,:]\n",
    "\n",
    "#also filter pickles and dicom paths for later, just in case\n",
    "pickles = list(compress(pickles,use))\n",
    "dicomPaths = list(compress(dicomPaths,use))\n",
    "\n",
    "#save X and Y for use in the ML dev notebook\n",
    "np.save(os.path.join(wsxDir,'X.npy'),X)\n",
    "np.save(os.path.join(wsxDir,'Y.npy'),Y)\n",
    "np.save(os.path.join(wsxDir,'pxSize.npy'),pxSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics for the area of pcf....\n",
    "\n",
    "fatArea = np.sum(Y,axis=(1,2)) * pxSize/100 #in mm^2\n",
    "\n",
    "plt.hist(fatArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "negs = 54\n",
    "\n",
    "egs = np.random.randint(m,size = negs)\n",
    "\n",
    "ncols = 4\n",
    "nrows = np.ceil(negs/ncols)\n",
    "\n",
    "plt.figure(figsize = (5*ncols,5*nrows))\n",
    "#lets ave a look\n",
    "for i in range(negs):\n",
    "    \n",
    "    plt.subplot(nrows,ncols,i+1)\n",
    "    \n",
    "    show_image_with_masks(X[egs[i],:,:],Y[egs[i],:,:],{'linewidth':1,'color':'y'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
