{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to use The RCA framework to do QC on image segmentation, but using the exact same CNN used for doing the segmentation as the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json,clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mask_utils import iou\n",
    "\n",
    "from network_utils import augmentImageSequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model, and get them sorted in the same way as in the notebooks used to train models (i.e. same train/test split, random seed etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = './data/pericardial/wsx_round2/'\n",
    "\n",
    "#load data - these files created by extract_dcm_for_wsx.ipynb\n",
    "X = np.load(os.path.join(DataDir,'X.npy'))\n",
    "Y = np.load(os.path.join(DataDir,'Y.npy')).astype('float')\n",
    "pxArea = np.load(os.path.join(DataDir,'pxSize.npy'))\n",
    "pxSpacing = np.sqrt(pxArea)\n",
    "\n",
    "#ensure the shape is correct arrays saved were rank 3, so this changes to rank 4 (last dimension represents channels)\n",
    "X = X.reshape([*X.shape,1])\n",
    "Y = Y.reshape([*Y.shape,1])\n",
    "\n",
    "#do train/test split!\n",
    "# X_train, X_test, Y_train, Y_test,pxArea_train,pxArea_test,pxSpacing_train,pxSpacing_test = train_test_split(X, Y, pxArea,pxSpacing, test_size=0.2,random_state=101)\n",
    "\n",
    "X = X[:100,:,:,:]\n",
    "Y = Y[:100,:,:,:]\n",
    "\n",
    "#\n",
    "# M = X.shape[0]\n",
    "# MTest = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, need to load a model which can be used for the RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a model, just need one to play with.\n",
    "modelBaseName = './data/models/mrunet_2020-04-07_09:59' #THIS MODEL IS NOT A GOOD ONE BUT HAS BEEN SELECTED TO GIVE A WIDE SPREAD IN IOU ON TRAIN AND TEST SETS\n",
    "\n",
    "#load the model archistecture\n",
    "with open( modelBaseName + '.json', 'r') as json_file:\n",
    "    model = model_from_json( json_file.read() )\n",
    "    \n",
    "#get the weights\n",
    "model.load_weights(modelBaseName + '.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE! RCA uses a network output to train a classifier which can be applied to other labelled data. I plan to use as a starting point *the actual network* that was used to generate the segmentation. However, this will not work in the obvious way - training a network on its own output will result in the cost function ==0, and thus all gradients ==0. \n",
    "\n",
    "However, thresholding the network output first will work! as the network will never output 0/1, but some numbers close to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT = Adam(learning_rate = 1e-3,\n",
    "           beta_1 = 0.9,\n",
    "           beta_2 = 0.999,\n",
    "           amsgrad = False\n",
    "          )\n",
    "\n",
    "\n",
    "def retrain_model(model,x,y):#,optimizer):\n",
    "    \n",
    "    ''''''\n",
    "    \n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]) and np.all(model.input_shape[1:] == y.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    \n",
    "    assert x.shape[0] == 1 and y.shape[0]==1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    #threshold mask so that it can be used as a target for CNN\n",
    "    y = y > 0.5\n",
    "    \n",
    "    #make a complete local copy of the model so that it is not modified globally\n",
    "    weights = model.get_weights()\n",
    "    model_local = clone_model(model)\n",
    "    model_local.set_weights(weights)\n",
    "    \n",
    "    model_local.compile(optimizer = OPT, \n",
    "                        loss = 'binary_crossentropy'\n",
    "                       )\n",
    "    \n",
    "    model_local.fit(x=x,\n",
    "                    y=y,\n",
    "                    epochs = 10, #THINK ABOUT ME\n",
    "                    steps_per_epoch= 1, #obvs\n",
    "                    verbose=0\n",
    "                   )\n",
    "    \n",
    "    return model_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_val,Y_val):\n",
    "    \n",
    "    '''this function takes a model (presumably retrained on a predicted mask in order to do RCA) and evaluates it on the set of masks which are known'''\n",
    "\n",
    "#     assert np.all(X.shape==Y.shape),'looks like you have mismatched your images and masks'\n",
    "#     assert X.shape[0]>1,'you should only use this on more than one image. Are you doing what you think youre doing?\n",
    "    \n",
    "    \n",
    "    Y_pred = model.predict(X_val)\n",
    "    \n",
    "    ious = np.array([iou(Y_pred[m],Y_val[m]) for m in range(Y_pred.shape[0])])\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_RCA_evaluate(model,x,X_val,Y_val):\n",
    "\n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    assert x.shape[0] == 1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    y = model.predict(x)\n",
    "    \n",
    "    rca_model = retrain_model(model,x,y)\n",
    "    \n",
    "    ious = evaluate_model(rca_model,X_val,Y_val)\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should look at the iou spread over the whole thing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allious = evaluate_model(model,X,Y)\n",
    "\n",
    "plt.hist(allious,bins = np.arange(0,1.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets just get a single datapoint to play with..`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select an example image\n",
    "# np.random.seed(7)\n",
    "egInd = np.random.randint(X.shape[0])\n",
    "\n",
    "#get the IOU that we want to predict...\n",
    "trueIOU = allious[egInd]\n",
    "\n",
    "#get the actual image out and shaped correctly\n",
    "egX = X[egInd,:,:].reshape(1,*model.input_shape[1:])\n",
    "\n",
    "#get all images EXCEPT that one, from both X and Y\n",
    "mask = np.ones(X.shape[0],dtype=bool)\n",
    "mask[egInd] = False\n",
    "X_val = X[mask,:,:,:]\n",
    "Y_val = Y[mask,:,:,:]\n",
    "\n",
    "predictedIOUs = predict_and_RCA_evaluate(model,egX,X_val,Y_val)\n",
    "\n",
    "plt.hist(predictedIOUs,bins= np.arange(0,1.05,0.05),density=True)\n",
    "\n",
    "plt.plot([trueIOU,trueIOU],plt.ylim(),c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_ious(ind):\n",
    "    \n",
    "    #get the actual image out and shaped correctly\n",
    "    egX = X[egInd,:,:].reshape(1,*model.input_shape[1:])\n",
    "\n",
    "    #get all images EXCEPT that one, from both X and Y\n",
    "    mask = np.ones(X.shape[0],dtype=bool)\n",
    "    mask[egInd] = False\n",
    "    X_val = X[mask,:,:,:]\n",
    "    Y_val = Y[mask,:,:,:]\n",
    "\n",
    "    predictedIOUs = predict_and_RCA_evaluate(model,egX,X_val,Y_val)\n",
    "    \n",
    "    return predictedIOUs.reshape(1,-1)\n",
    "\n",
    "\n",
    "predIOUs = np.concatenate([get_predicted_ious(ind) for ind in range(X.shape[0])],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "\n",
    "y = np.max(predIOUs,axis=1)\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot([0,0],[1,1])\n",
    "plt.scatter(allious,y)\n",
    "plt.title(f'{pearsonr(allious,y)[0]**2:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (max)')                      \n",
    "\n",
    "y = np.median(predIOUs,axis=1)            \n",
    "plt.subplot(3,1,2)\n",
    "plt.plot([0,0],[1,1])\n",
    "plt.scatter(allious,y)\n",
    "plt.title(f'{pearsonr(allious,y)[0]**2:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (median)')                      \n",
    "  \n",
    "y = np.mean(predIOUs,axis=1)\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot([0,0],[1,1])\n",
    "plt.scatter(allious,y)\n",
    "plt.title(f'{pearsonr(allious,y)[0]**2:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (mean)')                      \n",
    "\n",
    "            \n",
    "plt.xlabel('true IOU')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0 CPU",
   "language": "python",
   "name": "tf2-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
