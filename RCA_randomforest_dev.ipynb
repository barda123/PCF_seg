{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCA uses a network output to train a classifier which can be applied to other labelled data. This notebook attempts to use random forest segmentation to achieve this.\n",
    "THIS STUFF WILL ONLY WORK ON IMAGES, NOT VOLUMES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json,clone_model\n",
    "\n",
    "from mask_utils import iou,dsc,mean_contour_distance,symmetric_hausdorff_distance\n",
    "\n",
    "from network_utils import augmentImageSequence, gpu_memory_limit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memory_limit(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model, and get them sorted in the same way as in the notebooks used to train models (i.e. same train/test split, random seed etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = './data/pericardial/wsx_round2/'\n",
    "\n",
    "#load data - these files created by extract_dcm_for_wsx.ipynb\n",
    "X = np.load(os.path.join(DataDir,'X.npy'))\n",
    "Y = np.load(os.path.join(DataDir,'Y.npy')).astype('float')\n",
    "pxArea = np.load(os.path.join(DataDir,'pxSize.npy'))\n",
    "pxSpacing = np.sqrt(pxArea)\n",
    "\n",
    "#ensure the shape is correct arrays saved were rank 3, so this changes to rank 4 (last dimension represents channels)\n",
    "X = X.reshape([*X.shape,1])\n",
    "Y = Y.reshape([*Y.shape,1])\n",
    "\n",
    "#do train/test split!\n",
    "X_train, X_test, Y_train, Y_test,pxArea_train,pxArea_test,pxSpacing_train,pxSpacing_test = train_test_split(X, Y, pxArea,pxSpacing, test_size=0.2,random_state=101)\n",
    "\n",
    "# X = X[:200,:,:,:]\n",
    "# Y = Y[:200,:,:,:]\n",
    "\n",
    "#\n",
    "# M = X.shape[0]\n",
    "# MTest = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, need to load a model which can be used for the RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a model, just need one to play with.\n",
    "modelBaseName = './data/models/mrunet_2020-04-07_09:59' #THIS MODEL IS NOT THE BEST ONE BUT HAS BEEN SELECTED TO GIVE A WIDE SPREAD IN IOU ON TRAIN AND TEST SETS\n",
    "\n",
    "#load the model archistecture\n",
    "with open( modelBaseName + '.json', 'r') as json_file:\n",
    "    model = model_from_json( json_file.read() )\n",
    "    \n",
    "#get the weights\n",
    "model.load_weights(modelBaseName + '.h5')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuboid_mean(image,cuboidRadii):\n",
    "\n",
    "    '''Takes the mean of \n",
    "    image is an image. \n",
    "    cuboidRadii is a tuple of ints, representing the radii of \n",
    "    actually the rectangular mean, as this will only work on images (not volumes or hypervolumes).'''\n",
    "    \n",
    "    #pad the image with edge pixels so that edges don't tend to 0 after convolution\n",
    "    pads = [(d,d) for d in cuboidRadii] # convert radii to symmetric tuples for each dimension\n",
    "    image = np.pad(image,pad_width=(pads),mode='edge')\n",
    "    \n",
    "    dim = [1+2*d for d in cuboidRadii] #only odd edge lengths allowed, as centers must be unambiguous\n",
    "    \n",
    "    #create block for convolution\n",
    "    block = np.ones(dim,dtype='float')\n",
    "    \n",
    "    #do the convolution\n",
    "    cuboidMean = signal.convolve(image,block,method = 'direct',mode='valid') #valid convolution will reduce size of array back to original dims.\n",
    "    \n",
    "    return cuboidMean\n",
    "    \n",
    "def cuboid_offset_mean_difference(image,cuboidRadii,offsets):\n",
    "    \n",
    "    '''nonlocal feature generation - takes the cuboid mean (actually rectangular mean) and subtracts it from each pixel, but offset by some dimensions specified by offset (which should contain x and y)'''\n",
    "    \n",
    "    #pad the edges using the offsets - which must be on the correct side i.e. before if negative, after if positive. This bit will work for higher-dimensions!\n",
    "    pads = []\n",
    "\n",
    "    for offset in offsets:\n",
    "        if offset < 0:\n",
    "            pads.append((abs(offset),0))\n",
    "        else:\n",
    "            pads.append((0,offset))\n",
    "    \n",
    "    image_padded = np.pad(image,pad_width=pads,mode='edge')\n",
    "    \n",
    "    #calculate the cuboid mean\n",
    "    cuboidMean = cuboid_mean(image_padded, cuboidRadii)\n",
    "        \n",
    "    #keep the bit corresponding to the original shape, allows elementwise subtractions\n",
    "    indices = []\n",
    "    for dim,offset in zip(cuboidMean.shape,offsets):\n",
    "        if offset < 0:\n",
    "            indices.append(slice(-dim,offset))\n",
    "        else:\n",
    "            indices.append(slice(offset,dim))\n",
    "            \n",
    "    cuboidMean = cuboidMean[tuple(indices)]\n",
    "    \n",
    "    cuboidMeanDifference = image - cuboidMean\n",
    "    \n",
    "    return cuboidMeanDifference\n",
    "\n",
    "def image2features(image):\n",
    "    \n",
    "    '''take an image (of arbitrary dimension) and convert it to an array of (npixels,nfeatures)'''\n",
    "    \n",
    "    npx = np.product(image.shape[:-1])\n",
    "    \n",
    "    nfeatures = image.shape[-1]\n",
    "    \n",
    "    features = image.reshape(npx,nfeatures)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def feature_engineer_function(nFeatures=100,maxRadius=5,maxOffset=20,random_seed = None):\n",
    "    \n",
    "    '''this function RETURNS A FUNCTION which can be used to process images into (npixels,nfeatures)'''\n",
    "    \n",
    "    #calculate the maximum number of unique parameter sets that can be generated with the maximum parameters specified.\n",
    "    maxParameterSets = maxRadius**2 * (maxOffset*2 - 1)**2\n",
    "    \n",
    "    assert maxParameterSets > nFeatures,'you are trying to generate more features than are mathematically possible (max is ' + str(maxParameterSets) + ')'\n",
    "    \n",
    "    #generate a big set of parameters that can be fed into \n",
    "    radii = np.random.randint(low=0,high=maxRadius,size=(nFeatures,2))\n",
    "    offsets = np.random.randint(low=-maxRadius+1,high=maxRadius,size=(nFeatures,2))\n",
    "\n",
    "    def feature_Function(image):\n",
    "        \n",
    "        #only need to use the cuboid_offset_mean_difference as cuboid_mean is a special case of this (with offsets = [0,0])    \n",
    "\n",
    "        feat = np.stack([cuboid_offset_mean_difference(image.squeeze(),radius,offset) for radius,offset in zip(radii,offsets)],axis=-1)        \n",
    "        feat = image2features(feat)\n",
    "        \n",
    "        return feat\n",
    "    \n",
    "    return feature_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rca_model(x,y):\n",
    "    \n",
    "    ''''''\n",
    "#     assert x.shape[0] == 1 and y.shape[0]==1, 'you can only do RCA on one image at a time! or alternatively the images are the wrong shape'\n",
    "    \n",
    "    #threshold mask so that it can be used as a target for another classifier\n",
    "    y = y > 0.5\n",
    "    \n",
    "    \n",
    "    #generate feature engineering function which can be reused\n",
    "    feature_Function = feature_engineer_function()\n",
    "       \n",
    "    #reshape multidimensional image into (npx,nfeatures) array\n",
    "    x = feature_Function(x)\n",
    "    print(x.shape)\n",
    "    y = image2features(y).flatten() #FIXME this only works for cases with one output class.\n",
    "    print(y.shape)\n",
    "    #instantiate model and fit - hyperparameters from Valindria at al 2017 currently\n",
    "    rca_model = RandomForestClassifier(n_estimators=50,\n",
    "                                   max_depth=30,\n",
    "                                   n_jobs=4, #don't be a dick\n",
    "                                  )\n",
    "    \n",
    "    rca_model.fit(x,y)\n",
    "    \n",
    "    return rca_model,feature_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rca_model(X[0].squeeze(),Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_val,Y_val):\n",
    "    \n",
    "    '''this function takes a model (presumably retrained on a predicted mask in order to do RCA) and evaluates it on the set of masks which are known'''\n",
    "\n",
    "#     assert np.all(X.shape==Y.shape),'looks like you have mismatched your images and masks'\n",
    "#     assert X.shape[0]>1,'you should only use this on more than one image. Are you doing what you think youre doing?\n",
    "    \n",
    "    \n",
    "    Y_pred = model.predict(X_val)\n",
    "    \n",
    "    ious = np.array([iou(Y_pred[m],Y_val[m]) for m in range(Y_pred.shape[0])])\n",
    "    \n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_RCA_evaluate(model,x,X_val,Y_val):\n",
    "\n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    assert x.shape[0] == 1, 'you can only do RCA on one image at a time!'\n",
    "    \n",
    "    y = model.predict(x)\n",
    "    \n",
    "    rca_model,feature_Function = train_rca_model(x,y)\n",
    "    \n",
    "    ious = evaluate_model(rca_model,X_val,Y_val)\n",
    "    \n",
    "    return ious#,mcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should look at the iou spread over the whole thing... The IOUs of all of the data we plan to use, to evaluate the *original* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueIOUs = evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "plt.hist(trueIOUs,bins = np.arange(0,1.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets just get a single datapoint to play with... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select an example image\n",
    "np.random.seed(7)\n",
    "egInd = np.random.randint(X_test.shape[0])\n",
    "\n",
    "#get the IOU that we want to predict...\n",
    "trueIOU = trueIOUs[egInd]\n",
    "\n",
    "#get the actual image out and shaped correctly\n",
    "egX = X_test[egInd,:,:].reshape(1,*model.input_shape[1:])\n",
    "\n",
    "#get all images EXCEPT that one, from both X and Y\n",
    "mask = np.ones(X_test.shape[0],dtype=bool)\n",
    "mask[egInd] = False\n",
    "X_val = X_test[mask,:,:,:]\n",
    "Y_val = Y_test[mask,:,:,:]\n",
    "\n",
    "predictedIOUs,fitHistory = predict_and_RCA_evaluate(model,egX,X_val,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there are considerations about which evaluation set should be used. It seems to me that thw whole point of this is to do with looking for similarities to the training set - so this should be used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the true IOU for all of the test set\n",
    "trueIOUs = evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "MTest =  X_test.shape[0]\n",
    "M = X_train.shape[0]\n",
    "\n",
    "predIOUs = np.zeros((MTest,M))\n",
    "\n",
    "#loop over each test set example\n",
    "for ind in range(MTest):\n",
    "\n",
    "    predIOUs[ind,:] = predict_and_RCA_evaluate(model,egX,X_train,Y_train,optimizer=OPT,epochs=EPOCHS,dataGenArgs=dataGenArgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "\n",
    "y = np.max(predIOUs,axis=1)\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title'r = ' + (f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (max)')                      \n",
    "\n",
    "y = np.median(predIOUs,axis=1)            \n",
    "plt.subplot(3,1,2)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title('r = ' + f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (median)')                      \n",
    "  \n",
    "y = np.mean(predIOUs,axis=1)\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title('r = ' + f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (mean)')                      \n",
    "\n",
    "            \n",
    "plt.xlabel('true IOU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that suuuuuucks. Give up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0 GPU",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
