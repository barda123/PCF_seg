{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCA uses a network output to train a classifier which can be applied to other labelled data. This notebook attempts to use random forest segmentation to achieve this.\n",
    "THIS STUFF WILL ONLY WORK ON IMAGES, NOT VOLUMES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json,clone_model\n",
    "\n",
    "from mask_utils import iou,dsc,mean_contour_distance,symmetric_hausdorff_distance,show_image_with_masks\n",
    "\n",
    "from network_utils import augmentImageSequence, gpu_memory_limit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memory_limit(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model, and get them sorted in the same way as in the notebooks used to train models (i.e. same train/test split, random seed etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = './data/pericardial/wsx_round2/'\n",
    "\n",
    "#load data - these files created by extract_dcm_for_wsx.ipynb\n",
    "X = np.load(os.path.join(DataDir,'X.npy'))\n",
    "Y = np.load(os.path.join(DataDir,'Y.npy')).astype('float')\n",
    "pxArea = np.load(os.path.join(DataDir,'pxSize.npy'))\n",
    "pxSpacing = np.sqrt(pxArea)\n",
    "\n",
    "#ensure the shape is correct arrays saved were rank 3, so this changes to rank 4 (last dimension represents channels)\n",
    "X = X.reshape([*X.shape,1])\n",
    "Y = Y.reshape([*Y.shape,1])\n",
    "\n",
    "#do train/test split!\n",
    "X_train, X_test, Y_train, Y_test,pxArea_train,pxArea_test,pxSpacing_train,pxSpacing_test = train_test_split(X, Y, pxArea,pxSpacing, test_size=0.2,random_state=101)\n",
    "\n",
    "# X = X[:200,:,:,:]\n",
    "# Y = Y[:200,:,:,:]\n",
    "\n",
    "#\n",
    "# M = X.shape[0]\n",
    "# MTest = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, need to load a model which can be used for the RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a model, just need one to play with.\n",
    "modelBaseName = './data/models/mrunet_2020-04-07_09:59' #THIS MODEL IS NOT THE BEST ONE BUT HAS BEEN SELECTED TO GIVE A WIDE SPREAD IN IOU ON TRAIN AND TEST SETS\n",
    "\n",
    "#load the model archistecture\n",
    "with open( modelBaseName + '.json', 'r') as json_file:\n",
    "    model = model_from_json( json_file.read() )\n",
    "    \n",
    "#get the weights\n",
    "model.load_weights(modelBaseName + '.h5')    \n",
    "\n",
    "\n",
    "#make predictions on the test set:\n",
    "Pred_test = model.predict(X_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuboid_mean(image,cuboidRadii):\n",
    "\n",
    "    '''Takes the mean of \n",
    "    image is an image. \n",
    "    cuboidRadii is a tuple of ints, representing the radii of \n",
    "    actually the rectangular mean, as this will only work on images (not volumes or hypervolumes).'''\n",
    "    \n",
    "    #pad the image with edge pixels so that edges don't tend to 0 after convolution\n",
    "    pads = [(d,d) for d in cuboidRadii] # convert radii to symmetric tuples for each dimension\n",
    "    image = np.pad(image,pad_width=(pads),mode='edge')\n",
    "    \n",
    "    dim = [1+2*d for d in cuboidRadii] #only odd edge lengths allowed, as centers must be unambiguous\n",
    "    \n",
    "    #create block for convolution\n",
    "    block = np.ones(dim,dtype='float')\n",
    "    \n",
    "    #do the convolution\n",
    "    cuboidMean = signal.convolve(image,block,method='auto',mode='valid') #valid convolution will reduce size of array back to original dims.\n",
    "    \n",
    "    return cuboidMean\n",
    "    \n",
    "def cuboid_offset_mean_difference(image,cuboidRadii,offsets):\n",
    "    \n",
    "    '''nonlocal feature generation - takes the cuboid mean (actually rectangular mean) and subtracts it from each pixel, but offset by some dimensions specified by offset (which should contain x and y)'''\n",
    "    \n",
    "    #pad the edges using the offsets - which must be on the correct side i.e. before if negative, after if positive. This bit will work for higher-dimensions!\n",
    "    pads = []\n",
    "\n",
    "    for offset in offsets:\n",
    "        if offset < 0:\n",
    "            pads.append((abs(offset),0))\n",
    "        else:\n",
    "            pads.append((0,offset))\n",
    "    \n",
    "    image_padded = np.pad(image,pad_width=pads,mode='edge')\n",
    "    \n",
    "    #calculate the cuboid mean\n",
    "    cuboidMean = cuboid_mean(image_padded, cuboidRadii)\n",
    "        \n",
    "    #keep the bit corresponding to the original shape, allows elementwise subtractions\n",
    "    indices = []\n",
    "    for dim,offset in zip(cuboidMean.shape,offsets):\n",
    "        if offset < 0:\n",
    "            indices.append(slice(-dim,offset))\n",
    "        else:\n",
    "            indices.append(slice(offset,dim))\n",
    "            \n",
    "    cuboidMean = cuboidMean[tuple(indices)]\n",
    "    \n",
    "    cuboidMeanDifference = image - cuboidMean\n",
    "    \n",
    "    return cuboidMeanDifference\n",
    "\n",
    "def image2features(image):\n",
    "    \n",
    "    '''take an image (of arbitrary dimension) and convert it to an array of (npixels,nfeatures)'''\n",
    "    \n",
    "    npx = np.product(image.shape[:-1])\n",
    "    \n",
    "    nfeatures = image.shape[-1]\n",
    "    \n",
    "    features = image.reshape(npx,nfeatures)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def feature_engineer_function(nFeatures=500,maxRadius=4,maxOffset=8,random_seed = None,prior = None):\n",
    "    \n",
    "    '''this function RETURNS A FUNCTION which can be used to process images into (npixels,nfeatures)\n",
    "    default arguments: Zikic et al allow a max radius of 5mm (approx 3px in my dataset), and a max offset of 15mm (approx 8px in my dataset).\n",
    "    Valindria et al use 10000 features, but their problem is 3D. 10000^(2/3) = 464, so perhaps a default of 500 is appropriate for a 2D problem?????????\n",
    "    also allows the addition of precomputed priors\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #calculate the maximum number of unique parameter sets that can be generated with the maximum parameters specified.\n",
    "    maxParameterSets = maxRadius**2 * (maxOffset*2 - 1)**2\n",
    "    \n",
    "    assert maxParameterSets > nFeatures,'you are trying to generate more features than are mathematically possible (max is ' + str(maxParameterSets) + ')'\n",
    "    \n",
    "    #set random state so that deterministic behaviour can be guaranteed if necessary\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    #generate a big set of parameters that can be fed into \n",
    "    radii = np.random.randint(low=0,high=maxRadius,size=(nFeatures,2))\n",
    "    offsets = np.random.randint(low=-maxRadius+1,high=maxRadius,size=(nFeatures,2))\n",
    "\n",
    "    def feature_Function(image):\n",
    "        \n",
    "        #only need to use the cuboid_offset_mean_difference as cuboid_mean is a special case of this (with offsets = [0,0])    \n",
    "\n",
    "#         [image.squeeze()]\n",
    "        feat = np.stack([cuboid_offset_mean_difference(image.squeeze(),radius,offset) for radius,offset in zip(radii,offsets)],axis=-1)\n",
    "\n",
    "        if prior is not None:\n",
    "            feat = np.concatenate([feat,prior],axis=-1)\n",
    "        \n",
    "        feat = image2features(feat)\n",
    "        \n",
    "        return feat\n",
    "    \n",
    "    return feature_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess_and_predict_model_wrapper():\n",
    "    \n",
    "    '''this class exists to allow all preprocessing of images to be incorporated into an object used for '''\n",
    "    \n",
    "    \n",
    "    def __init__(self,model,preprocessing_function):\n",
    "        \n",
    "        self.model = model #this should be, for example, an sklearn model instance\n",
    "        self.preprocessing_function = preprocessing_function #a function which preprocesses inputs for use in the model\n",
    "        \n",
    "    def predict(self,x):\n",
    "\n",
    "        #preprocess the input (which is likely an image)\n",
    "        xProcessed = self.preprocessing_function(x)\n",
    "\n",
    "        #actually make the prediction\n",
    "        y = self.model.predict(xProcessed)\n",
    "\n",
    "        #convert the output back into the image shape, preserving channels if they exist\n",
    "        y = y.reshape(*x.shape[:-1],-1)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "def train_rca_model(x,y,featureOptions={},forestOptions={}):\n",
    "    \n",
    "    '''optional dictionaries for feature engineering and random forest'''\n",
    "#     assert x.shape[0] == 1 and y.shape[0]==1, 'you can only do RCA on one image at a time! or alternatively the images are the wrong shape'\n",
    "    \n",
    "    #threshold mask so that it can be used as a target classifier\n",
    "    y = y > 0.5\n",
    "    \n",
    "    #generate feature engineering function which can be reused\n",
    "    feature_Function = feature_engineer_function(**featureOptions)\n",
    "       \n",
    "    #reshape multidimensional image into (npx,nfeatures) array, and add features\n",
    "    x = feature_Function(x)\n",
    "\n",
    "    y = image2features(y).flatten() #FIXME this only works for cases with two output classes.\n",
    "    \n",
    "    rf = RandomForestClassifier(**forestOptions) #pass options in\n",
    "    \n",
    "    rf.fit(x,y)\n",
    "    \n",
    "    #now, wrap the function for preprocessing images and the model into a single object with a predict() method:\n",
    "    rcaModel = preprocess_and_predict_model_wrapper(model=rf,preprocessing_function=feature_Function)\n",
    "    \n",
    "    return rcaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_val,Y_val):\n",
    "    \n",
    "    '''this function takes a model (presumably retrained on a predicted mask in order to do RCA) and evaluates it on the set of masks which are known'''\n",
    "\n",
    "    #FIXME THIS IS FUCKING LAZY AND WILL FALL OVER REALLY EASILY\n",
    "    try:\n",
    "        Y_pred = model.predict(X_val)\n",
    "    except:\n",
    "        Y_pred = [model.predict(X) for X in X_val]\n",
    "    \n",
    "    ious = np.array([iou(Y_pred[m],Y_val[m]) for m in range(len(Y_pred))])\n",
    "    \n",
    "    #FIXME add some more metrics fam (mcd,hd,dsc)\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_evaluate(x,pred,X_val,Y_val,featureOptions={},forestOptions={}):\n",
    "    \n",
    "    assert np.all(model.input_shape[1:] == x.shape[1:]),'image input shape and model input do not match - have you reshaped the image correctly?'\n",
    "    assert x.shape[0] == 1, 'you can only do RCA on one image at a time! or you might have reshaped image wrongly....'\n",
    "    \n",
    "    #mean of the evaluation output across the subjects - corresponds to voxelwise probability of each class. FIXME BE A BIT FUCKING CLEVERERER\n",
    "    prior = np.mean(Y_val,axis=0)\n",
    "    \n",
    "    featureOptions['prior'] = prior\n",
    "    \n",
    "    rcaModel = train_rca_model(x,pred,featureOptions,forestOptions)\n",
    "    \n",
    "    ious = evaluate_model(rcaModel,X_val,Y_val)\n",
    "    \n",
    "    return ious#,mcd FIXME!!!! this should ultimately return only a single number/collection of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should look at the iou spread over the whole thing... The IOUs of all of the data we plan to use, to evaluate the *original* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueIOUs = evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "plt.hist(trueIOUs,bins = np.arange(0,1.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there are considerations about which evaluation set should be used. It seems to me that thw whole point of this is to do with looking for similarities to the training set - so this should be used to get the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets just get a single datapoint to play with... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTest =  X_test.shape[0]\n",
    "M = X_train.shape[0]\n",
    "\n",
    "\n",
    "#select an example image\n",
    "np.random.seed(21)\n",
    "egInd = np.random.randint(X_test.shape[0])\n",
    "\n",
    "#get the IOU that we want to predict...\n",
    "trueIOU = trueIOUs[egInd]\n",
    "\n",
    "#get the actual image out and shaped correctly\n",
    "egX = X_test[egInd,:,:].reshape(1,*model.input_shape[1:])\n",
    "\n",
    "egPred = Pred_test[egInd,:,:].reshape(1,*model.input_shape[1:])\n",
    "\n",
    "#select a subset of training set images for quicker evaluation of the RCA method\n",
    "MVal = 50\n",
    "sel4val = np.random.randint(0,M,MVal)\n",
    "\n",
    "X_val = X_train[sel4val,:,:,:]\n",
    "Y_val = Y_train[sel4val,:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcaModel = train_rca_model(egX,egPred)\n",
    "\n",
    "negs = 25\n",
    "\n",
    "egs = np.random.choice(range(MVal), negs, replace=False)\n",
    "\n",
    "ncols = 5\n",
    "nrows = np.ceil(negs/ncols)\n",
    "\n",
    "plt.figure(figsize = (5*ncols,5*nrows))\n",
    "\n",
    "imShape = X.shape[1:-1]\n",
    "\n",
    "#FIRST show the real segmentation i.e. MANUAL, MACHINE AND RCA \n",
    "plt.subplot(nrows,ncols,1)\n",
    "    \n",
    "manualMask,rcaMask = egY.reshape(imShape), rcaModel.predict(egX.reshape(imShape))\n",
    "\n",
    "show_image_with_masks(image = egX.reshape(imShape),\n",
    "                      masks = [manualMask,predY.reshape(imShape),rcaMask],\n",
    "                      maskOptions = [{'linewidth':1,'color':'g'},{'linewidth':1.5,'color':'b'},{'linewidth':1,'color':'r'}]\n",
    "                     )\n",
    "\n",
    "plt.title('ORIGINAL IMAGE')\n",
    "\n",
    "for i in range(1,negs):\n",
    "    \n",
    "    plt.subplot(nrows,ncols,i+1)\n",
    "    \n",
    "    manualMask,rcaMask = Y_val[egs[i]].reshape(imShape) > 0.5, rcaModel.predict(X_val[egs[i]].reshape(imShape))\n",
    "    \n",
    "    pxS = pxSpacing[egs[i]]\n",
    "\n",
    "    \n",
    "    show_image_with_masks(image = X_val[egs[i],:,:].reshape(imShape),\n",
    "                          masks = [manualMask,rcaMask],\n",
    "                          maskOptions = [{'linewidth':1,'color':'g'},{'linewidth':1,'color':'r'}]\n",
    "                         )\n",
    "    \n",
    "    plt.title('iou = ' + f'{iou(manualMask,rcaMask):.03}' + '\\n' + \n",
    "              'hd = ' + f'{symmetric_hausdorff_distance(manualMask,rcaMask,pxS):.03}' + '\\n' +\n",
    "              'mcd = ' + f'{mean_contour_distance(manualMask,rcaMask,pxS):.03}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictedIOUs = rca_evaluate(egX,egPred,X_val,Y_val)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(predictedIOUs,bins= np.arange(0,1.05,0.05),density=True,label = 'IOU of evaluation examples after retraining')\n",
    "plt.plot([trueIOU,trueIOU],plt.ylim(),c='r',label = 'true IOU')\n",
    "plt.xlabel('iou')\n",
    "plt.ylabel('probability density')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(evaluate_model(model,X_val,Y_val),predictedIOUs,label = 'evaluation set')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.plot([0,1],[trueIOU,trueIOU],c='r',label = 'true IOU')\n",
    "plt.plot([0,1],[0,1],c='k',label = 'line of unity')\n",
    "plt.xlabel('original IOU')\n",
    "plt.ylabel('IOU after retraining')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the true IOU for all of the test set\n",
    "trueIOUs = evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "predIOUs = np.zeros((MTest,MVal))\n",
    "\n",
    "#loop over each test set example\n",
    "for ind in range(MTest):\n",
    "\n",
    "    egX = X_test[ind,:,:,:].reshape(1,208,208,1)\n",
    "    \n",
    "    predIOUs[ind,:] = rca_evaluate(egX,egPred,X_val,Y_val,featureOptions,forestOptions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "\n",
    "y = np.max(predIOUs,axis=1)\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title( 'r = ' + f'{pearsonr(trueIOUs,y)[0]:.02}') \n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (max)')                      \n",
    "\n",
    "y = np.median(predIOUs,axis=1)            \n",
    "plt.subplot(3,1,2)Â¬\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title('r = ' + f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (median)')                      \n",
    "  \n",
    "y = np.mean(predIOUs,axis=1)\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot([0,1],[0,1],c='k')\n",
    "plt.scatter(trueIOUs,y)\n",
    "plt.title('r = ' + f'{pearsonr(trueIOUs,y)[0]:.02}')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('predicted IOU (mean)')                      \n",
    "\n",
    "            \n",
    "plt.xlabel('true IOU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that doesn't work as well as could be hoped. Lets do grid search over the whole thing? You never know...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureOptions = dict(nFeatures=500,\n",
    "                      maxRadius=4,\n",
    "                      maxOffset=8,\n",
    "                      random_seed=None\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestOptions = dict(n_estimators=50,\n",
    "                     criterion='gini', #Zikic et al use entropy\n",
    "                     max_depth=30,\n",
    "                     class_weight='balanced',#balance class weights as this problem is imbalanced (as are most semantic segmentation tasks...)\n",
    "                     n_jobs=None, #don't be a dick\n",
    "#                      random_state=101, #determinism\n",
    "                     min_samples_split = 10,\n",
    "                     max_features = 'auto',\n",
    "                     \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all parameters and their values for a fuck-off grid search\n",
    "nFeatures = [50,100,500,1000]\n",
    "maxRadius = [5,10,15,20]\n",
    "maxOffset = [5,10,15,20]\n",
    "\n",
    "n_estimators = [30,50,100,200,500]\n",
    "max_features = ['auto','sqrt']\n",
    "bootstrap = [True,False]\n",
    "criterion = ['gini','entropy']\n",
    "min_samples_split = [3,10,30,100]\n",
    "min_samples_leaf = [1,3,10,30,100]\n",
    "max_depth = [10,30,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(params):\n",
    "    \n",
    "    featureOptions = {'random_seed':304} #DETERMINISM\n",
    "    \n",
    "    featureOptions['nFeatures'],featureOptions['maxRadius'],featureOptions['maxOffset'] = params\n",
    "    \n",
    "    return featureOptions\n",
    "    \n",
    "featureParams = [p.flatten() for p in np.meshgrid(nFeatures,maxRadius,maxOffset)]\n",
    "\n",
    "featureDicts = [get_feature_dict(p) for p in zip(*featureParams)]\n",
    "\n",
    "print(len(featureDicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_feature_eng(image,paramDict):\n",
    "    \n",
    "#     paramDict['prior'] = np.mean(Y_val,axis=0)\n",
    "    \n",
    "    func = feature_engineer_function(**paramDict)\n",
    "    \n",
    "    return func(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parallelise preprocessing of both test set and evaluation set\n",
    "\n",
    "MTest = 50\n",
    "X_test = X_test[:MTest]\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "X_test_features = []\n",
    "X_val_features = []\n",
    "\n",
    "with Pool(processes=4) as p:\n",
    "    \n",
    "    for i,f in enumerate(featureDicts):\n",
    "        \n",
    "        feats =  p.starmap(parallelize_feature_eng,zip(X_test,[f]*MTest ))\n",
    "        name = './Xfeat' + str(i) + '.pickle'\n",
    "        X_test_features.append(name)\n",
    "        pickle.dump(feats,open(name,'wb'))\n",
    "        \n",
    "        feats =  p.starmap(parallelize_feature_eng,zip(X_val,[f]*MVal )) \n",
    "        name = './Xval' + str(i) + '.pickle'\n",
    "        X_val_features.append(name)\n",
    "        pickle.dump(feats,open(name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest_dict(params):\n",
    "    \n",
    "    forestOptions = {'class_weight':'balanced'}#balance class weights as this problem is imbalanced (as are most semantic segmentation tasks...)\n",
    "    \n",
    "    forestOptions['n_estimators'],forestOptions['max_features'],forestOptions['bootstrap'],forestOptions['criterion'],forestOptions['min_samples_split'],forestOptions['min_samples_leaf'],forestOptions['max_depth'] = params\n",
    "    \n",
    "    return forestOptions\n",
    "    \n",
    "#all parameter sets as dictionaries\n",
    "forestParams = [p.flatten() for p in np.meshgrid(n_estimators,max_features,bootstrap,criterion,min_samples_split,min_samples_leaf,max_depth)]\n",
    "forestParams = [get_forest_dict(d) for d in list(zip(*forestParams))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all combinations of feature/function indices and forest parameters\n",
    "featureIndices = range(len(featureDicts))\n",
    "allParams = list(zip(*[x.flatten() for x in np.meshgrid(featureIndices,forestParams)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_from_params(params):\n",
    "    \n",
    "    #extract hyperParameters\n",
    "    featureIndex,forestOptions = params\n",
    "\n",
    "    #get the processed images using featureIndex\n",
    "    ims_preprocessed = pickle.load(open(X_test_features[featureIndex],'rb')\n",
    "    \n",
    "    #now use featureIndex to get the preprocessed evaluation images\n",
    "    X_val_preprocessed = pickle.load(open(X_val_features[featureIndex],'rb')\n",
    "    \n",
    "    #loop over the processed images\n",
    "    predIOUs = []\n",
    "    \n",
    "    for m in range(MTest):\n",
    "        \n",
    "        imageFeatures = ims_preprocessed[m]\n",
    "                \n",
    "        #get the flattened predictions using featureIndex\n",
    "        pred = Pred_test[m].flatten()\n",
    "\n",
    "        #instantiate and train the RCA model using forestOptions\n",
    "        rca_model = RandomForestClassifier(**forestOptions)\n",
    "\n",
    "        \n",
    "        rca_model.fit(imageFeatures,pred)\n",
    "        #how well does the model do during fitting?\n",
    "#         print(iou(rca_model.predict(imageFeatures),pred))\n",
    "        \n",
    "        \n",
    "        #calculate iou between RCA predictions and evaluation masks, and take the max, adding to list\n",
    "        predIOUs.append( max([iou(rca_model.predict(x)>0.5,y.flatten()>0.5) for x,y in zip(X_val_preprocessed,Y_val)]) )        \n",
    "\n",
    "    #get r between the max ious and the true ious\n",
    "    r = pearsonr(predIOUs,trueIOUs[:len(predIOUs)])\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=4) as p:\n",
    "    correlations = p.map(get_r_from_params,allParams)\n",
    "    pickle.dump(correlations,open('./correlations.pickle','rb'))\n",
    "    \n",
    "    r,p = map(np.array,zip(correlations))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0 GPU",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
